{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e9abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Delta Spark 4.0.0\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc3f8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando datos en dataframes\n",
    "df_customer = spark.read.format(\"delta\").load(\"../sql/dw_bronze/customer\")\n",
    "df_product = spark.read.format(\"delta\").load(\"../sql/dw_bronze/product\")\n",
    "df_so_detail = spark.read.format(\"delta\").load(\"../sql/dw_bronze/so_detail\")\n",
    "df_so_header = spark.read.format(\"delta\").load(\"../sql/dw_bronze/so_header.write\")\n",
    "df_s_territory =spark.read.format(\"delta\").load(\"../sql/dw_bronze/s_terrotory.write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03509e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contando cantidad de nulos por campo en cada tabla\n",
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "def porcentaje_nulos_por_columna(df_customer):\n",
    "    total = df_customer.count()  # Cuenta cuantas filas tiene el dataframe\n",
    "\n",
    "    return df_customer.select([\n",
    "        # Para cada columna, contamos los valores que son nulos y calculamos el %\n",
    "        (count(when(col(c).isNull(), c)) / total * 100).alias(c)\n",
    "        for c in df_customer.columns  # Recorremos todas las columnas del DataFrame\n",
    "    ])\n",
    "porcentaje_nulos_por_columna(df_customer).show() #StoreID con 93.26% de nulos\n",
    "\n",
    "\n",
    "def porcentaje_nulos_por_columna(df_product):\n",
    "    total = df_product.count()  # Cuenta cuantas filas tiene el dataframe\n",
    "\n",
    "    return df_product.select([\n",
    "        # Para cada columna, contamos los valores que son nulos y calculamos el %\n",
    "        (count(when(col(c).isNull(), c)) / total * 100).alias(c)\n",
    "        for c in df_product.columns  # Recorremos todas las columnas del DataFrame\n",
    "    ])\n",
    "porcentaje_nulos_por_columna(df_product).show() #StoreID con 93.26% de nulos\n",
    "\n",
    "\n",
    "def porcentaje_nulos_por_columna(df_so_detail):\n",
    "    total = df_so_detail.count()  # Cuenta cuantas filas tiene el dataframe\n",
    "\n",
    "    return df_so_detail.select([\n",
    "        # Para cada columna, contamos los valores que son nulos y calculamos el %\n",
    "        (count(when(col(c).isNull(), c)) / total * 100).alias(c)\n",
    "        for c in df_so_detail.columns  # Recorremos todas las columnas del DataFrame\n",
    "    ])\n",
    "porcentaje_nulos_por_columna(df_so_detail).show() #StoreID con 93.26% de nulos\n",
    "\n",
    "\n",
    "def porcentaje_nulos_por_columna(df_so_header):\n",
    "    total = df_so_header.count()  # Cuenta cuantas filas tiene el dataframe\n",
    "\n",
    "    return df_so_header.select([\n",
    "        # Para cada columna, contamos los valores que son nulos y calculamos el %\n",
    "        (count(when(col(c).isNull(), c)) / total * 100).alias(c)\n",
    "        for c in df_so_header.columns  # Recorremos todas las columnas del DataFrame\n",
    "    ])\n",
    "porcentaje_nulos_por_columna(df_so_header).show() #StoreID con 93.26% de nulos\n",
    "\n",
    "\n",
    "def porcentaje_nulos_por_columna(df_s_territory):\n",
    "    total = df_s_territory.count()  # Cuenta cuantas filas tiene el dataframe\n",
    "\n",
    "    return df_s_territory.select([\n",
    "        # Para cada columna, contamos los valores que son nulos y calculamos el %\n",
    "        (count(when(col(c).isNull(), c)) / total * 100).alias(c)\n",
    "        for c in df_s_territory.columns  # Recorremos todas las columnas del DataFrame\n",
    "    ])\n",
    "porcentaje_nulos_por_columna(df_s_territory).show() #StoreID con 93.26% de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce715b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando duplicados y nulos de los ID, dropeando campos de auditoria\n",
    "#df_customer.show() # Eliminar nulos y duplicados (CustomerID) - Eliminar campos (fecha_carga, archivo_origen)\n",
    "#df_product.show() # Eliminar nulos y duplicados (ProductID) - Eliminar campos (fecha_carga, archivo_origen)\n",
    "#df_so_detail.show() # Eliminar nulos y duplicados (SalesOrderID) - Eliminar campos (fecha_carga, archivo_origen)\n",
    "#df_so_header.show() # Eliminar nulos y duplicados (SalesOrderID) - Eliminar campos (fecha_carga, archivo_origen)\n",
    "#df_s_territory.show() # Eliminar nulos y duplicados (TerritoryID) - Eliminar campos (fecha_carga, archivo_origen)\n",
    "\n",
    "df_customer_limpio = df_customer.drop_duplicates([\"CustomerID\"]).filter(\"CustomerID IS NOT NULL\").drop(\"fecha_carga\", \"archivo_origen\")\n",
    "df_product_limpio = df_product.dropDuplicates([\"ProductID\"]).filter(\"ProductID IS NOT NULL\").drop(\"fecha_carga\", \"archivo_origen\")\n",
    "df_so_detail_limpio = df_so_detail.dropDuplicates([\"SalesOrderID\"]).filter(\"SalesOrderID IS NOT NULL\").drop(\"fecha_carga\", \"archivo_origen\")\n",
    "df_so_header_limpio = df_so_header.dropDuplicates([\"SalesOrderID\"]).filter(\"SalesOrderID IS NOT NULL\").drop(\"fecha_carga\", \"archivo_origen\")\n",
    "df_s_territory_limpio = df_s_territory.dropDuplicates([\"TerritoryID\"]).filter(\"TerritoryID IS NOT NULL\").drop(\"fecha_carga\", \"archivo_origen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_limpio.show(1) \n",
    "df_product_limpio.show(1) \n",
    "df_so_detail_limpio.show(1) \n",
    "df_so_header_limpio.show(1) \n",
    "df_s_territory_limpio.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac87a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modificando tipos de datos\n",
    "#df_customer_limpio.printSchema() # Campos con tipos de datos correctos\n",
    "#df_product_limpio.printSchema() # ModifiedDate, SellStartDate (Pasar a timestamp)\n",
    "#df_so_detail_limpio.printSchema() # Campos con tipos de datos correctoscustomer\n",
    "#df_so_header_limpio.printSchema() # Campos con tipos de datos correctos\n",
    "#df_s_territory_limpio.printSchema() # Campos con tipos de datos correctos\n",
    "from pyspark.sql.functions import col\n",
    "df_customer_limpio_tipo = df_customer_limpio\n",
    "df_product_limpio_tipo = df_product_limpio\\\n",
    "    .withColumn(\"ModifiedDate\",col(\"ModifiedDate\").cast(\"timestamp\"))\\\n",
    "    .withColumn(\"SellStartDate\",col(\"SellStartDate\").cast(\"timestamp\"))\n",
    "df_so_detail_limpio_tipo = df_so_detail_limpio\n",
    "df_so_header_limpio_tipo = df_so_header_limpio\n",
    "df_s_territory_limpio_tipo = df_s_territory_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9326b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renombrando campos a español\n",
    "df_customer_rename = df_customer_limpio_tipo\\\n",
    "    .withColumnRenamed(\"CustomerID\",\"ClienteID\")\\\n",
    "    .withColumnRenamed(\"PersonID\",\"PersonaID\")\\\n",
    "    .withColumnRenamed(\"StoreID\",\"TiendaID\")\\\n",
    "    .withColumnRenamed(\"TerritoryID\",\"TerritorioID\")\\\n",
    "    .withColumnRenamed(\"AccountNumber\",\"Numero_cuenta\")\\\n",
    "    .withColumnRenamed(\"rowguid\",\"guia_filas\")\\\n",
    "    .withColumnRenamed(\"ModifiedDate\",\"Fecha_modificacion\")\n",
    "\n",
    "df_product_rename = df_product_limpio_tipo\\\n",
    "    .withColumnRenamed(\"ProductID\",\"ProductoID\")\\\n",
    "    .withColumnRenamed(\"Name\",\"Nombre\")\\\n",
    "    .withColumnRenamed(\"ProductNumber\",\"Numero_producto\")\\\n",
    "    .withColumnRenamed(\"MakeFlag\",\"Flag\")\\\n",
    "    .withColumnRenamed(\"FinishedGoodsFlag\",\"Flag_terminados\")\\\n",
    "    .withColumnRenamed(\"SafetyStockLevel\",\"Seguridad_stock\")\\\n",
    "    .withColumnRenamed(\"ReorderPoint\",\"Punto_reorden\")\\\n",
    "    .withColumnRenamed(\"StandardCost\",\"Costo_estandar\")\\\n",
    "    .withColumnRenamed(\"ListPrice\",\"Precio_lista\")\\\n",
    "    .withColumnRenamed(\"Size\",\"Tamaño\")\\\n",
    "    .withColumnRenamed(\"SizeUnitMeasureCode\",\"Codigo_medida_unidad\")\\\n",
    "    .withColumnRenamed(\"WeightUnitMeasureCode\",\"Codigo_medida_peso\")\\\n",
    "    .withColumnRenamed(\"Weight\",\"Peso\")\\\n",
    "    .withColumnRenamed(\"DaysToManufacture\",\"Dias_fabricar\")\\\n",
    "    .withColumnRenamed(\"ProductLine\",\"Linea_Producto\")\\\n",
    "    .withColumnRenamed(\"Class\",\"Clase\")\\\n",
    "    .withColumnRenamed(\"Style\",\"Estilo\")\\\n",
    "    .withColumnRenamed(\"ProductSubcategoryID\",\"SubcategoriaID_producto\")\\\n",
    "    .withColumnRenamed(\"ProductModelID\",\"ModeloID_producto\")\\\n",
    "    .withColumnRenamed(\"SellStartDate\",\"Fecha_inicio_venta\")\\\n",
    "    .withColumnRenamed(\"SellEndDate\",\"Fecha_finalizacion_venta\")\\\n",
    "    .withColumnRenamed(\"DiscontinuedDate\",\"Fecha_descontinuacion\")\\\n",
    "    .withColumnRenamed(\"rowguid\",\"guia_filas\")\\\n",
    "    .withColumnRenamed(\"ModifiedDate\",\"Fecha_modificacion\")\n",
    "\n",
    "df_so_detail_rename = df_so_detail_limpio_tipo\\\n",
    "    .withColumnRenamed(\"SalesOrderID\",\"PedidoID\")\\\n",
    "    .withColumnRenamed(\"SalesOrderDetailID\",\"DetalleID\")\\\n",
    "    .withColumnRenamed(\"CarrierTrackingNumber\",\"Numero_seguimiento\")\\\n",
    "    .withColumnRenamed(\"OrderQty\",\"Cantidad_pedido\")\\\n",
    "    .withColumnRenamed(\"ProductID\",\"ProductoID\")\\\n",
    "    .withColumnRenamed(\"SpecialOfferID\",\"OfertaEsp_ID\")\\\n",
    "    .withColumnRenamed(\"UnitPrice\",\"Precio_Unitario\")\\\n",
    "    .withColumnRenamed(\"UnitPriceDiscount\",\"Desc_precio_uni\")\\\n",
    "    .withColumnRenamed(\"LineTotal\",\"Linea_total\")\\\n",
    "    .withColumnRenamed(\"rowguid\",\"guia_filas\")\\\n",
    "    .withColumnRenamed(\"ModifiedDate\",\"Fecha_modificacion\")\n",
    "\n",
    "df_so_header_rename = df_so_header_limpio_tipo\\\n",
    "    .withColumnRenamed(\"SalesOrderID\", \"PedidoID\")\\\n",
    "    .withColumnRenamed(\"RevisionNumber\", \"NumeroRevision\")\\\n",
    "    .withColumnRenamed(\"OrderDate\", \"FechaPedido\")\\\n",
    "    .withColumnRenamed(\"DueDate\", \"FechaVencimiento\")\\\n",
    "    .withColumnRenamed(\"ShipDate\", \"FechaEnvio\")\\\n",
    "    .withColumnRenamed(\"Status\", \"Estado\")\\\n",
    "    .withColumnRenamed(\"OnlineOrderFlag\", \"PedidoOnline\")\\\n",
    "    .withColumnRenamed(\"SalesOrderNumber\", \"NumeroPedido\")\\\n",
    "    .withColumnRenamed(\"PurchaseOrderNumber\", \"NumeroOrdenCompra\")\\\n",
    "    .withColumnRenamed(\"AccountNumber\", \"NumeroCuenta\")\\\n",
    "    .withColumnRenamed(\"CustomerID\", \"ClienteID\")\\\n",
    "    .withColumnRenamed(\"SalesPersonID\", \"VendedorID\")\\\n",
    "    .withColumnRenamed(\"TerritoryID\", \"TerritorioID\")\\\n",
    "    .withColumnRenamed(\"BillToAddressID\", \"DireccionFacturaID\")\\\n",
    "    .withColumnRenamed(\"ShipToAddressID\", \"DireccionEnvioID\")\\\n",
    "    .withColumnRenamed(\"ShipMethodID\", \"MetodoEnvioID\")\\\n",
    "    .withColumnRenamed(\"CreditCardID\", \"TarjetaCreditoID\")\\\n",
    "    .withColumnRenamed(\"CreditCardApprovalCode\", \"CodigoAprobacionTC\")\\\n",
    "    .withColumnRenamed(\"CurrencyRateID\", \"TasaCambioID\")\\\n",
    "    .withColumnRenamed(\"SubTotal\", \"Subtotal\")\\\n",
    "    .withColumnRenamed(\"TaxAmt\", \"MontoImpuesto\")\\\n",
    "    .withColumnRenamed(\"Freight\", \"CostoEnvio\")\\\n",
    "    .withColumnRenamed(\"TotalDue\", \"TotalAPagar\")\\\n",
    "    .withColumnRenamed(\"Comment\", \"Comentario\")\\\n",
    "    .withColumnRenamed(\"rowguid\", \"guia_filas\")\\\n",
    "    .withColumnRenamed(\"ModifiedDate\", \"FechaModificacion\")\n",
    "\n",
    "df_s_territory_rename = df_s_territory_limpio_tipo\\\n",
    "    .withColumnRenamed(\"TerritoryID\", \"TerritorioID\")\\\n",
    "    .withColumnRenamed(\"Name\", \"Nombre\")\\\n",
    "    .withColumnRenamed(\"CountryRegionCode\", \"CodigoPaisRegion\")\\\n",
    "    .withColumnRenamed(\"Group\", \"Continente\")\\\n",
    "    .withColumnRenamed(\"SalesYTD\", \"VentasAcumuladasAno\")\\\n",
    "    .withColumnRenamed(\"SalesLastYear\", \"VentasAnoAnterior\")\\\n",
    "    .withColumnRenamed(\"CostYTD\", \"CostoAcumuladoAno\")\\\n",
    "    .withColumnRenamed(\"CostLastYear\", \"CostoAnoAnterior\")\\\n",
    "    .withColumnRenamed(\"rowguid\", \"guia_filas\")\\\n",
    "    .withColumnRenamed(\"ModifiedDate\", \"FechaModificacion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f2856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Haciendo JOINS con la finalidad de crear tablas dimensionales\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, sequence, explode, to_date, year, month, quarter, dayofweek, date_format, when\n",
    "\n",
    "#CREANDO DF_VENTAS\n",
    "df_ventas = df_so_header_rename.join(\n",
    "    df_so_detail_rename,\n",
    "    on=\"PedidoID\",\n",
    "    how = \"inner\"\n",
    ").select(\n",
    "    \"PedidoID\",\n",
    "    \"ClienteID\",\n",
    "    \"TerritorioID\",\n",
    "    \"FechaPedido\",\n",
    "    \"ProductoID\",\n",
    "    \"Cantidad_pedido\",\n",
    "    \"Precio_Unitario\",\n",
    "    \"Linea_total\"   \n",
    ")\n",
    "#df_ventas.show()\n",
    "\n",
    "#CREANDO DF_PRODUCTOS\n",
    "df_productos = df_product_rename\\\n",
    "    .select(\n",
    "        \"ProductoID\",\n",
    "        \"Nombre\",\n",
    "        \"Numero_producto\",\n",
    "        \"Precio_lista\"\n",
    "    )\n",
    "#df_productos.show()\n",
    "\n",
    "#CREANDO DF_CLIENTES\n",
    "df_clientes = df_customer_rename\\\n",
    "    .select(\n",
    "        \"ClienteID\",\n",
    "        \"TerritorioID\"\n",
    "    )\n",
    "#df_clientes.show()\n",
    "\n",
    "df_territorio = df_s_territory_rename\\\n",
    "    .select(\n",
    "        \"TerritorioID\",\n",
    "        \"Nombre\",\n",
    "        \"CodigoPaisRegion\",\n",
    "        \"Continente\"\n",
    "    )\n",
    "#df_territorio.show()\n",
    "\n",
    "# Creando rango de fechas directamente con Spark\n",
    "df_rango = spark.sql(\"\"\"\n",
    "SELECT explode(sequence(to_date('2015-01-01'), to_date('2025-12-31'), interval 1 day)) as Fecha\n",
    "\"\"\")\n",
    "\n",
    "# Agregando columnas necesarias\n",
    "df_fecha = df_rango.withColumn(\"FechaID\", date_format(\"Fecha\", \"yyyyMMdd\").cast(\"int\"))\\\n",
    "    .withColumn(\"Año\", year(\"Fecha\"))\\\n",
    "    .withColumn(\"Mes\", month(\"Fecha\"))\\\n",
    "    .withColumn(\"Trimestre\", quarter(\"Fecha\"))\\\n",
    "    .withColumn(\"DiaSemana\", dayofweek(\"Fecha\"))\\\n",
    "    .withColumn(\"NombreMes\", date_format(\"Fecha\", \"MMMM\"))\\\n",
    "    .withColumn(\"NombreDia\", date_format(\"Fecha\", \"EEEE\"))\\\n",
    "    .withColumn(\"EsFinDeSemana\", when(dayofweek(\"Fecha\").isin(1, 7), 1).otherwise(0))\\\n",
    "    .select(\"FechaID\", \"Fecha\", \"Año\", \"Mes\", \"Trimestre\", \"NombreMes\", \"NombreDia\", \"DiaSemana\", \"EsFinDeSemana\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ebe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ALMACENANDO DATAFRAMES EN AMBIENTE\n",
    "df_ventas.write.format(\"delta\").mode(\"overwrite\").save(\"../sql/dw_silver/dim_ventas\")\n",
    "df_productos.write.format(\"delta\").mode(\"overwrite\").save(\"../sql/dw_silver/dim_productos\")\n",
    "df_clientes.write.format(\"delta\").mode(\"overwrite\").save(\"../sql/dw_silver/dim_clientes\")\n",
    "df_territorio.write.format(\"delta\").mode(\"overwrite\").save(\"../sql/dw_silver/dim_territorio\")\n",
    "df_fecha.write.format(\"delta\").mode(\"overwrite\").save(\"../sql/dw_silver/dim_fecha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
